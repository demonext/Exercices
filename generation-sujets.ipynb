{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération des exercices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /home/hathout/Developpements/2022-Demonext/Generation-exercices/Demonext/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.read_csv('names.csv')\n",
    "people = people.sort_values('last')\n",
    "people = people['first'] + '_' + people['last']\n",
    "people = list(people.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = pd.read_csv('Data/sem.csv', delimiter=',')\n",
    "specif = {}\n",
    "ex = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('Data/data-iser.csv')\n",
    "\n",
    "specif['exun'] = {'type':'exlex+class', 'nbex':5, 'nbclass':2}\n",
    "\n",
    "ex['exun'] = {}\n",
    "ex['exun']['adj'] = data1['verbe'][(data1['cat_base']=='adj')]\n",
    "ex['exun']['noun'] = data1['verbe'][(data1['cat_base']=='noun')]\n",
    "ex['exun']['prefix'] = data1['verbe'][(data1['cat_base']=='prefix')]\n",
    "ex['exun']['simplex'] = data1['verbe'][(data1['cat_base']=='simplex')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('Data/data-ite.csv')\n",
    "\n",
    "specif['exdeux'] = {'type':'exlex+class', 'nbex':4, 'nbclass':2}\n",
    "\n",
    "ex['exdeux'] = {}\n",
    "ex['exdeux']['absurdite'] = data2['dérivé'][(data2['procédé']=='ité') & (data2['allomorphie?']=='0') & (data2['m=f']==1)]\n",
    "ex['exdeux']['adaptabilite'] = data2['dérivé'][(data2['procédé']=='ité') & (data2['allomorphie?'].isin(['able~abil'])) & (data2['m=f']==1)]\n",
    "ex['exdeux']['biodiversite'] = data2['dérivé'][data2['procédé']=='pfx']\n",
    "ex['exdeux']['bonte'] = data2['dérivé'][(data2['procédé']=='té') & (data2['allomorphie?']=='0') & (data2['m=f']==1)]\n",
    "ex['exdeux']['parite'] = data2['dérivé'][(data2['procédé']=='ité') & (data2['allomorphie?'].isin(['el~al','aire~ar'])) & (data2['m=f']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_csv('Data/data-denominaux.csv', delimiter=',')\n",
    "data3['couple'] = data3['graph_1'] + ' -- ' + data3['graph_2']\n",
    "data3 = data3.join(sem.set_index('graphie'), on='graph_2')\n",
    "\n",
    "specif['extrois'] = {'type':'exlex', 'nbex':2}\n",
    "\n",
    "ex['extrois'] = {}\n",
    "ex['extrois']['panifier'] = data3['couple'][(data3['cstr_1'].isin(['Xifier', 'Xiser'])) & (data3['Artifact']==1)]\n",
    "ex['extrois']['embrasser'] =  data3['couple'][(data3['cstr_1'] == 'enX') & (data3['Body']==1)]\n",
    "ex['extrois']['vampiriser'] = data3['couple'][(data3['cstr_1'].isin(['Xifier', 'Xiser'])) & (data3['Person']==1)]\n",
    "\n",
    "specif['extroisbis'] = {'type':'exlex', 'nbex':5}\n",
    "ex['extroisbis'] = {}\n",
    "ex['extroisbis']['pain'] = sem['graphie'][(sem['Artifact'] == 1)]\n",
    "ex['extroisbis']['bras'] = sem['graphie'][(sem['Body'] == 1)]\n",
    "ex['extroisbis']['vampire'] = sem['graphie'][(sem['Person'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = pd.read_csv('Data/data-conversion.csv', delimiter=',')\n",
    "data4['couple'] = data4['graph_1'] + ' -- ' + data4['graph_2']\n",
    "data4 = data4.join(sem.set_index('graphie'), on='graph_2')\n",
    "\n",
    "specif['exquatre'] = {'type':'exlex', 'nbex':2}\n",
    "\n",
    "ex['exquatre'] = {}\n",
    "ex['exquatre']['zigzaguer'] = data4['couple'][(data4['cat_1'] == 'V') & (data4['Act']==1)]\n",
    "ex['exquatre']['vitrioler'] = data4['couple'][(data4['cat_1'] == 'V') & (data4['Substance']==1)]\n",
    "ex['exquatre']['ventriloquer'] = data4['couple'][(data4['cat_1'] == 'V') & (data4['Person']==1)]\n",
    "\n",
    "specif['exquatrebis'] = {'type':'exlex', 'nbex':5}\n",
    "\n",
    "ex['exquatrebis'] = {}\n",
    "ex['exquatrebis']['zigzag'] = sem['graphie'][(sem['Act'] == 1)]\n",
    "ex['exquatrebis']['vitriol'] = sem['graphie'][(sem['Substance'] == 1)]\n",
    "ex['exquatrebis']['ventriloque'] = sem['graphie'][(sem['Person'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = pd.read_csv('Data/data-histoire.csv', delimiter=',')\n",
    "data5['couple'] = data5['graph_1'] + ' -- ' + data5['graph_2']\n",
    "\n",
    "specif['excinq'] = {'type':'exlex', 'nbex':5}\n",
    "\n",
    "ex['excinq'] = {}\n",
    "ex['excinq']['cogestionnaire'] = data5['couple'][(data5['cat_1'] == 'Adj') & (data5['cat_2']== 'V') & (data5['complexite'] == 'complexe') & (data5['orientation'] == 'des2as')]\n",
    "ex['excinq']['poulailler'] = data5['couple'][(data5['cat_1'].isin(['Nm', 'Nf', 'Npx'])) & (data5['cat_2'].isin(['Nm', 'Nf', 'Npx'])) & (data5['complexite'] == 'complexe') & (data5['orientation'] == 'des2as')]\n",
    "ex['excinq']['langagier'] = data5['couple'][(data5['cat_1'] == 'Adj') & (data5['cat_2'].isin(['Nm', 'Nf', 'Npx'])) & (data5['complexite'] == 'complexe') & (data5['orientation'] == 'des2as')]\n",
    "ex['excinq']['bitumisation'] = data5['couple'][(data5['cat_1'].isin(['Nm', 'Nf', 'Npx'])) & (data5['cat_2'] == 'V')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6 = pd.read_csv('Data/data-nouvelle-histoire.csv', delimiter=',')\n",
    "data6['couple'] = data6['graph_1'] + ' -- ' + data6['graph_2']\n",
    "\n",
    "specif['exsix'] = {'type':'exlex', 'nbex':1}\n",
    "\n",
    "ex['exsix'] = {}\n",
    "ex['exsix']['antigrippal'] = data6['couple'][(data6['cat_1'] == 'Adj') & (data6['cat_2'].isin(['Nm', 'Nf', 'Npx'])) & (data6['type_cstr_1'] == 'pre-suf') & (data6['cstr_2'] == 'X')]\n",
    "ex['exsix']['postglaciaire'] = data6['couple'][(data6['cat_1'] == 'Adj') & (data6['cat_2'].isin(['Nm', 'Nf', 'Npx'])) & (data6['type_cstr_1'] == 'pre-suf') & (data6['orientation'] == 'indirect')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data7 = pd.read_csv('Data/data-indirect-simple.csv', delimiter=',')\n",
    "data7['couple'] = data7['graph_1'] + ' -- ' + data7['graph_2']\n",
    "\n",
    "specif['exsept'] = {'type':'exlex', 'nbex':1}\n",
    "\n",
    "ex['exsept'] = {}\n",
    "ex['exsept']['applicateur'] = data7['couple'][(data7['cat_1'].isin(['Nm', 'Nf', 'Npx'])) & (data7['cat_2'].isin(['Nm', 'Nf', 'Npx'])) & (data7['type_cstr_1'] == 'suf') & (data7['type_cstr_2'] == 'suf') & (data7['orientation'] == 'indirect') & (data7['complexite'] == 'simple')]\n",
    "ex['exsept']['contestataire'] =  data7['couple'][(data7['cat_1'] == 'Adj') & (data7['cat_2'].isin(['Nm', 'Nf', 'Npx'])) & (data7['type_cstr_1'] == 'suf') & (data7['type_cstr_2'] == 'suf') & (data7['orientation'] == 'indirect') & (data7['complexite'] == 'simple')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data8 = pd.read_csv('Data/data-variation.csv', delimiter=',')\n",
    "\n",
    "specif['exhuit'] = {'type':'exlist', 'nbex':1}\n",
    "\n",
    "data8 = data8[data8['cat_2']  == 'Nm']\n",
    "data8['duplic'] = data8.graph_2.duplicated(keep='last')\n",
    "data8x = data8[['graph_1', 'graph_2']][data8['duplic'] == True].copy()\n",
    "data8x['graph_1'] = data8x['graph_2']\n",
    "data8y = pd.concat([data8[['graph_1', 'graph_2']], data8x]).drop_duplicates()\n",
    "masky = data8y.graph_2.duplicated(keep=False)\n",
    "data8z = data8y[masky].groupby(['graph_2']).graph_1.apply(list).reset_index(name='variantes')\n",
    "\n",
    "ex['exhuit'] = {}\n",
    "ex['exhuit'] = data8z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data9 = pd.read_csv('Data/data-decalages.csv', delimiter=',')\n",
    "data9['couple'] = data9['graph_1'] + ' -- ' + data9['graph_2']\n",
    "\n",
    "specif['exneuf'] = {'type':'exlex', 'nbex':1}\n",
    "\n",
    "ex['exneuf'] = {}\n",
    "ex['exneuf']['cartesianisme'] = data9['couple'][(data9['cstr_1'] == 'Xianisme') & (data9['cstr_2'] == 'X') & (data9['complexite'] == 'motiv-sem')]\n",
    "ex['exneuf']['urbanisme'] = data9['couple'][(data9['cstr_1'] == 'Xanisme') & (data9['cstr_2'] == 'X') & (data9['complexite'] == 'motiv-sem')]\n",
    "ex['exneuf']['historicisme'] = data9['couple'][(data9['cstr_1'] == 'Xicisme') & (data9['cstr_2'] == 'X') & (data9['complexite'] == 'motiv-sem')]\n",
    "ex['exneuf']['cellularisme'] = data9['couple'][(data9['cstr_1'] == 'Xarisme') & (data9['cstr_2'] == 'X') & (data9['complexite'] == 'motiv-sem')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for etudiant in people:\n",
    "    enonce = ''\n",
    "    enonce += '\\\\newcommand{{\\\\student}}{{{0}}}\\n'.format(' '.join(etudiant.split('_')))\n",
    "    \n",
    "    for exo in ex:\n",
    "        match specif[exo]['type']:\n",
    "            case 'exlex':\n",
    "                for extype in sorted(ex[exo].keys()):\n",
    "                    exlex = list(ex[exo][extype].sample(specif[exo]['nbex']))\n",
    "                    enonce += '\\\\newcommand{{\\\\{0}}}{{\\\\label{{{0}}} {1}}}\\n'.format(extype + exo, ', '.join(sorted(exlex))) \n",
    "            case 'exlex+class':\n",
    "                exa_classer = []\n",
    "                for extype in sorted(ex[exo].keys()):\n",
    "                    exemples = list(ex[exo][extype].sample(specif[exo]['nbex'] + specif[exo]['nbclass']))\n",
    "                    exlex = exemples[:specif[exo]['nbex']]\n",
    "                    exa_classer  += exemples[specif[exo]['nbex']:]\n",
    "                    enonce += '\\\\newcommand{{\\\\{0}}}{{\\\\label{{{0}}} {1}}}\\n'.format(extype + exo, ', '.join(sorted(exlex)))\n",
    "                enonce += '\\\\newcommand{{\\\\aclasser{0}}}{{{1}}}\\n'.format(exo, ', '.join(sorted(exa_classer)))    \n",
    "            case 'exlist':\n",
    "                exlist = sorted(set(ex[exo].sample(specif[exo]['nbex']).iloc[0]['variantes']))\n",
    "                enonce += '\\\\newcommand{{\\\\{0}}}{{\\\\label{{{0}}} {1}}}\\n'.format(exo, ', '.join(exlist))         \n",
    "\n",
    "    file = open('latexvars','w')\n",
    "    file.write(enonce)\n",
    "    file.close()\n",
    "    !cat enonces-preamble.tex latexvars enonces-body.tex > {'enonces_' + etudiant + '.tex'}\n",
    "    !xelatex {'enonces_'+ etudiant +'.tex'}\n",
    "    !xelatex {'enonces_'+ etudiant +'.tex'}\n",
    "    !mv {'enonces_' + etudiant + '.pdf'} {'sujets/'}\n",
    "    !rm {'*' + etudiant + '*'}\n",
    "    !rm latexvars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
